{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "# import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.engine = nn.Sequential(\n",
    "                nn.Linear(784,512,bias=False),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Linear(512,256,bias=False),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Linear(256, 256,bias=False),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Linear(256, 10,bias=False)\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        ret = self.engine(x)\n",
    "        return ret\n",
    "    \n",
    "\n",
    "def get_datasets(*args, **kwargs):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor()\n",
    "#             transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainset = torchvision.datasets.MNIST(train=True, transform=transform, *args, **kwargs)\n",
    "    testset = torchvision.datasets.MNIST(train=False, transform=transform, *args, **kwargs)\n",
    "    return trainset, testset\n",
    "\n",
    "def get_dataloaders(trainset, testset, batch_size=100, num_worker=4):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_worker)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_worker)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "mlp = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_ = 0.002\n",
    "optimizer = optim.SGD(mlp.engine.parameters(), lr=lr_)\n",
    "\n",
    "\n",
    "trainset, testset = get_datasets(root='./data', download=True)\n",
    "trainloader, testloader = get_dataloaders(trainset, testset, batch_size=100, num_worker=16)\n",
    "loss_ = np.zeros(15)\n",
    "gradient = np.zeros((4,15))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './mnist_mlp.pth'\n",
    "torch.save(mlp.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "mlp.load_state_dict(torch.load(PATH), strict=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = mlp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW=6\n",
    "BX=6\n",
    "VBLMAX = 0.8 \n",
    "T0 = 100e-12\n",
    "kn = 220e-6\n",
    "Vt = 0.4\n",
    "alpha = 1.8\n",
    "CBL = 270e-15\n",
    "VWL = 0.9\n",
    "Icell = kn*np.power(VWL-Vt,alpha) # Ideal cell current of the discharge path\n",
    "delta_VBL_LSB = T0*Icell/CBL #The voltage difference on VBL created by the LSB\n",
    "kclip = VBLMAX/delta_VBL_LSB \n",
    "#kclip = 10000+VBLMAX/delta_VBL_LSB\n",
    "sigma_Vt = 23.8e-3\n",
    "sigma_D = alpha*sigma_Vt/(VWL-Vt)\n",
    "\n",
    "class MLP_DIMA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_DIMA, self).__init__()\n",
    "        self.engine = nn.Sequential(\n",
    "                nn.Linear(784,512,bias=False),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                DIMALinear(512,256,bias=False,var=sigma_D,layer_index = 2),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Linear(256, 256,bias=False),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                DIMALinear(256, 10,bias=False,var=sigma_D,layer_index = 3)\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        ret = self.engine(x)\n",
    "        return ret\n",
    "    \n",
    "# def get_datasets(*args, **kwargs):\n",
    "#     transform = transforms.Compose(\n",
    "#         [\n",
    "#             transforms.ToTensor(),\n",
    "# #             transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     trainset = torchvision.datasets.MNIST(train=True, transform=transform, *args, **kwargs)\n",
    "#     testset = torchvision.datasets.MNIST(train=False, transform=transform, *args, **kwargs)\n",
    "#     return trainset, testset\n",
    "\n",
    "# def get_dataloaders(trainset, testset, batch_size=100, num_worker=4):\n",
    "#     trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_worker)\n",
    "#     testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_worker)\n",
    "\n",
    "#     return trainloader, testloader\n",
    "\n",
    "def quantizeInput(X,BX):\n",
    "    X = np.minimum(X,1.0-np.power(2.0,-BX))\n",
    "    Xbs = []\n",
    "    for i in range(BX):\n",
    "        Xbi = np.greater_equal(X,0.5).astype(float)\n",
    "        Xbs.append(Xbi)\n",
    "        X = 2.0*X - Xbi\n",
    "    carry = np.greater_equal(X,0.5).astype(float)\n",
    "    for i in range(BX):\n",
    "        j=BX-1-i\n",
    "        Xbs[j] = Xbs[j]+carry\n",
    "        carry = np.greater(Xbs[j],1.5).astype(float)\n",
    "        Xbs[j] = Xbs[j]*np.not_equal(Xbs[j],2.0)\n",
    "    return Xbs\n",
    "def reconstructInput(Xbs,BX):\n",
    "    X=np.zeros_like(Xbs[0])\n",
    "    for l in range(BX):\n",
    "        multiplier = np.power(0.5,l+1.0)\n",
    "        X+=Xbs[l]*multiplier\n",
    "        X.astype(float)\n",
    "    return X\n",
    "\n",
    "# def quantizeWeight(W,BW):\n",
    "#     W = np.minimum(W,1.0-np.power(2.0,-(BW-1.0)))\n",
    "#     Wbs = []\n",
    "#     Wbi = np.less(W,0).astype(float)\n",
    "#     Wbs.append(Wbi)\n",
    "#     W = (W + Wbi)\n",
    "#     for i in range(BW-1):\n",
    "#         Wbi = np.greater_equal(W,0.5).astype(float)\n",
    "#         Wbs.append(Wbi)\n",
    "#         W = 2.0*W - Wbi\n",
    "#     carry = np.greater_equal(W,0.5).astype(float)\n",
    "#     for i in range(BW):#-1):\n",
    "#         j=BW-1-i\n",
    "#         Wbs[j] = Wbs[j]+carry\n",
    "#         carry = np.greater(Wbs[j],1.5).astype(float)\n",
    "#         Wbs[j] = Wbs[j]*np.not_equal(Wbs[j],2.0)\n",
    "#     return Wbs\n",
    "def quantizeWeight(W,BW):\n",
    "    W = torch.min(W,(1.0-(2**(-(BW-1.0))))*torch.ones_like(W))\n",
    "    Wbs = []\n",
    "    Wbi = torch.lt(W,torch.zeros_like(W)).float()\n",
    "    Wbs.append(Wbi)\n",
    "    W = (W + Wbi)\n",
    "    for i in range(BW-1):\n",
    "        Wbi = torch.ge(W,0.5*torch.ones_like(W)).float()\n",
    "        Wbs.append(Wbi)\n",
    "        W = 2.0*W - Wbi\n",
    "    carry = torch.ge(W,0.5*torch.ones_like(W)).float()\n",
    "    for i in range(BW):#-1):\n",
    "        j = BW-1-i\n",
    "        Wbs[j] = Wbs[j]+carry\n",
    "        carry = torch.gt(Wbs[j],1.5*torch.ones_like(Wbs[j])).float()\n",
    "        Wbs[j] = Wbs[j]*torch.ne(Wbs[j],2.0*torch.ones_like(Wbs[j]))\n",
    "    return Wbs\n",
    "\n",
    "# def reconstructWeight(Wbs,BW):\n",
    "#     W=np.zeros_like(Wbs[0])\n",
    "#     for j in range(BW):\n",
    "#         multiplier = np.power(0.5,j)\n",
    "#         if (j==0):\n",
    "#             multiplier=-1.0\n",
    "#         W+=Wbs[j]*multiplier\n",
    "#     return W\n",
    "def reconstructWeight(Wbs,BW):\n",
    "    W = torch.zeros_like(Wbs[0])\n",
    "    for j in range(BW):\n",
    "        multiplier = (0.5)**j\n",
    "        if (j == 0):\n",
    "            multiplier = -1.0\n",
    "        W += Wbs[j] * multiplier\n",
    "    return W\n",
    "\n",
    "class DIMALinear(nn.Linear):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, var: sigma_D = 0, layer_index = 0) -> None:\n",
    "        super(DIMALinear, self).__init__(in_features,out_features)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        self.noise = np.random.normal(0,sigma_D,(BW,self.weight.size()[0],self.weight.size()[1]))\n",
    "        print(self.weight.size())\n",
    "        self.layer_index = layer_index\n",
    "\n",
    "    def quantize_activations(self,input):\n",
    "        if(self.layer_index != 0):\n",
    "            input = torch.clamp(input,0,6) / 6\n",
    "            input = 6 * torch.min(torch.round(input*(2**BX))*(2**(-BX)) ,(1.0-(2**(-BX)))*torch.ones_like(input))\n",
    "            \n",
    "        else:\n",
    "            input = torch.min(torch.round(input*(2**BX))*(2**(-BX)) ,(1.0-(2**(-BX)))*torch.ones_like(input))\n",
    "        return input\n",
    "    def quantize_outputs(self,output):\n",
    "        output = torch.clamp(output,-6,6)\n",
    "        output = torch.min(torch.round((output/6)*(2**(BW-1.0)))*(2.0**(1.0-BW)),(1.0-(2.0**(1.0-BW)))*torch.ones_like(output))\n",
    "        output = output * 6\n",
    "        return output \n",
    "               \n",
    "    def quantize_weights(self):\n",
    "#         weight = self.weight.data.numpy()\n",
    "        weight_q = quantizeWeight(self.weight.data,BW)\n",
    "        for b in range(BW-1):\n",
    "            weight_q[b+1] = weight_q[b+1]*(1+self.noise[b])\n",
    "        weight = reconstructWeight(weight_q,BW)\n",
    "        Wmax = kclip*np.power(2.0,-(BW-1))\n",
    "#         weight = np.clip(weight,-Wmax,Wmax)\n",
    "        weight = torch.clamp(weight,-Wmax,Wmax)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        return weight \n",
    "#         self.weight = nn.Parameter(torch.from_numpy(weight))\n",
    "#         self.weight = nn.Parameter(self.weight.float())\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        weight = self.quantize_weights()\n",
    "        input = self.quantize_activations(input)\n",
    "        if(self.weight.size()[1] > 256):\n",
    "            inputs = []\n",
    "            weights = []\n",
    "            val = (self.weight.size()[1] // 256) + 1\n",
    "            for i in range (val):\n",
    "                if(i != val-1):\n",
    "                    inputs.append(input[:,(i*256):(255+(i*256))])\n",
    "                    weights.append(self.weight[:,(i*256):(255+(i*256))])\n",
    "                else:\n",
    "                    m = nn.ZeroPad2d((0,self.weight.size()[1]-(256*i),0,0))\n",
    "                    temp_w = m(self.weight[:,(i*256):])\n",
    "                    temp_i = m(input[:,(i*256):])\n",
    "                    inputs.append(temp_i)\n",
    "                    weights.append(temp_w)\n",
    "            output = torch.zeros(input.size()[0],self.weight.size()[0])\n",
    "            for i in range (val):\n",
    "                output += self.quantize_outputs(F.linear(inputs[i],weights[i]))\n",
    "#         print(self.weight.size(),input.size())\n",
    "#         print(torch.max(input))\n",
    "        else:\n",
    "            output = F.linear(input, self.weight)\n",
    "            output = self.quantize_outputs(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW=6\n",
    "BX=6\n",
    "VBLMAX = 0.8 \n",
    "T0 = 100e-12\n",
    "kn = 220e-6\n",
    "Vt = 0.4\n",
    "alpha = 1.8\n",
    "CBL = 270e-15\n",
    "VWL = 0.9\n",
    "Icell = kn*np.power(VWL-Vt,alpha) # Ideal cell current of the discharge path\n",
    "delta_VBL_LSB = T0*Icell/CBL #The voltage difference on VBL created by the LSB\n",
    "kclip = VBLMAX/delta_VBL_LSB \n",
    "#kclip = 10000+VBLMAX/delta_VBL_LSB\n",
    "sigma_Vt = 23.8e-3\n",
    "sigma_D = alpha*sigma_Vt/(VWL-Vt)\n",
    "\n",
    "def quantizeWeight(W,BW):\n",
    "    W = torch.min(W,(1.0-(2**(-(BW-1.0))))*torch.ones_like(W))\n",
    "    Wbs = []\n",
    "    Wbi = torch.lt(W,torch.zeros_like(W)).float()\n",
    "    Wbs.append(Wbi)\n",
    "    W = (W + Wbi)\n",
    "    for i in range(BW-1):\n",
    "        Wbi = torch.ge(W,0.5*torch.ones_like(W)).float()\n",
    "        Wbs.append(Wbi)\n",
    "        W = 2.0*W - Wbi\n",
    "    carry = torch.ge(W,0.5*torch.ones_like(W)).float()\n",
    "    for i in range(BW):#-1):\n",
    "        j = BW-1-i\n",
    "        Wbs[j] = Wbs[j]+carry\n",
    "        carry = torch.gt(Wbs[j],1.5*torch.ones_like(Wbs[j])).float()\n",
    "        Wbs[j] = Wbs[j] * torch.ne(Wbs[j],(2*torch.ones_like(Wbs[j])))\n",
    "    return Wbs\n",
    "\n",
    "def reconstructWeight(Wbs,BW):\n",
    "    W = torch.zeros_like(Wbs[0])\n",
    "    for j in range(BW):\n",
    "        multiplier = (0.5)**j\n",
    "        if (j == 0):\n",
    "            multiplier = -1.0\n",
    "        W += Wbs[j] * multiplier\n",
    "    return W\n",
    "\n",
    "class DIMALinear(nn.Linear):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, var: sigma_D = 0, layer_index = 0) -> None:\n",
    "        super(DIMALinear, self).__init__(in_features,out_features)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        self.noise = np.random.normal(0,sigma_D,(BW,self.weight.size()[0],self.weight.size()[1]))\n",
    "        print(self.weight.size())\n",
    "        self.layer_index = layer_index\n",
    "\n",
    "    def quantize_activations(self,input):\n",
    "        if(self.layer_index != 0):\n",
    "            input = torch.clamp(input,0,6) / 6\n",
    "            input = 6 * torch.min(self.round_f(input*(2**BX))*(2**(-BX)) ,(1.0-(2**(-BX)))*torch.ones_like(input))\n",
    "        else:\n",
    "            input = torch.min(self.round_f(input*(2**BX))*(2**(-BX)) ,(1.0-(2**(-BX)))*torch.ones_like(input))\n",
    "        return input\n",
    "    def quantize_outputs(self,output):\n",
    "        output = torch.clamp(output,-6,6)\n",
    "        output = torch.min(self.round_f((output/6)*(2**(BW-1.0)))*(2.0**(1.0-BW)),(1.0-(2.0**(1.0-BW)))*torch.ones_like(output))\n",
    "        output = output * 6\n",
    "        return output \n",
    "               \n",
    "    def round_f(self, x): #rounds a number to the nearest integer with STE for gradients\n",
    "        x_r = torch.round(x)\n",
    "        x_g = x\n",
    "        return (x_r - x_g).detach() + x_g\n",
    "    \n",
    "    def quantize_weights(self):\n",
    "        weight_q = quantizeWeight(self.weight.data,BW)\n",
    "        for b in range(BW-1):\n",
    "            weight_q[b+1] = weight_q[b+1]*(1+self.noise[b])\n",
    "        weight = reconstructWeight(weight_q,BW)\n",
    "        Wmax = kclip*np.power(2.0,-(BW-1))\n",
    "        weight = torch.clamp(weight,-Wmax,Wmax)\n",
    "        return (weight - self.weight).detach() + self.weight\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        weight = self.quantize_weights()\n",
    "#         self.weight = nn.Parameter(weight)\n",
    "        input = self.quantize_activations(input)\n",
    "        if(self.weight.size()[1] > 256):\n",
    "            inputs = []\n",
    "            weights = []\n",
    "            val = (self.weight.size()[1] // 256) + 1\n",
    "            for i in range (val):\n",
    "                if(i != val-1):\n",
    "                    inputs.append(input[:,(i*256):(256+(i*256))])\n",
    "                    weights.append(weight[:,(i*256):(256+(i*256))])\n",
    "                else:\n",
    "                    m = nn.ZeroPad2d((0,(256*(i+1))-self.weight.size()[1],0,0))\n",
    "                    temp_w = m(weight[:,(i*256):])\n",
    "                    temp_i = m(input[:,(i*256):])\n",
    "                    inputs.append(temp_i)\n",
    "                    weights.append(temp_w)\n",
    "            output = torch.zeros(input.size()[0],self.weight.size()[0])\n",
    "            for i in range (val):\n",
    "                output += self.quantize_outputs(F.linear(inputs[i],weights[i]))\n",
    "        else:\n",
    "            output = F.linear(input, weight)\n",
    "            output = self.quantize_outputs(output)\n",
    "        return output\n",
    "    \n",
    "class MLP_DIMA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_DIMA, self).__init__()\n",
    "        self.engine = nn.Sequential(\n",
    "                DIMALinear(784,512,bias=False,var=sigma_D,layer_index=0),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                DIMALinear(512,256,bias=False,var=sigma_D,layer_index=1),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                DIMALinear(256, 256,bias=False,var=sigma_D,layer_index=2),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                DIMALinear(256, 10,bias=False,var=sigma_D,layer_index = 3)\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        ret = self.engine(x)\n",
    "        return ret\n",
    "    \n",
    "# def get_datasets(*args, **kwargs):\n",
    "#     transform = transforms.Compose(\n",
    "#         [\n",
    "#             transforms.ToTensor(),\n",
    "# #             transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     trainset = torchvision.datasets.MNIST(train=True, transform=transform, *args, **kwargs)\n",
    "#     testset = torchvision.datasets.MNIST(train=False, transform=transform, *args, **kwargs)\n",
    "#     return trainset, testset\n",
    "\n",
    "# def get_dataloaders(trainset, testset, batch_size=100, num_worker=4):\n",
    "#     trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_worker)\n",
    "#     testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_worker)\n",
    "\n",
    "#     return trainloader, testloader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 256])\n",
      "torch.Size([10, 256])\n",
      "ACC: 51.38\n",
      "Time: 29.699488878250122\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# start_time = time.time()\n",
    "mlp_DIMA = MLP_DIMA()\n",
    "mlp_DIMA.load_state_dict(torch.load(PATH), strict=False)\n",
    "# BW=6\n",
    "# BX=6\n",
    "# VBLMAX = 0.8 \n",
    "# T0 = 100e-12\n",
    "# kn = 220e-6\n",
    "# Vt = 0.4\n",
    "# alpha = 1.8\n",
    "# CBL = 270e-15\n",
    "# VWL = 0.9\n",
    "# Icell = kn*np.power(VWL-Vt,alpha) # Ideal cell current of the discharge path\n",
    "# delta_VBL_LSB = T0*Icell/CBL #The voltage difference on VBL created by the LSB\n",
    "# kclip = VBLMAX/delta_VBL_LSB \n",
    "# #kclip = 10000+VBLMAX/delta_VBL_LSB\n",
    "# sigma_Vt = 23.8e-3\n",
    "# sigma_D = alpha*sigma_Vt/(VWL-Vt)\n",
    "\n",
    "time_ = []\n",
    "acc = []\n",
    "# for i in range (1):\n",
    "start_time = time.time()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = mlp_DIMA(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "time_.append(time.time() - start_time)\n",
    "acc.append(100 * correct / total)\n",
    "#     print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#         100 * correct / total))\n",
    "\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print('ACC:',np.average(np.array(acc)))\n",
    "print('Time:',np.average(np.array(time_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "lr_ = 0.0005\n",
    "optimizer = optim.SGD(mlp_DIMA.engine.parameters(), lr=lr_)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp_DIMA(inputs)\n",
    "\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "PATH_ = './mnist_mlp_dima.pth'\n",
    "torch.save(mlp_DIMA.state_dict(), PATH_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 88.49\n",
      "Time: 28.37289333343506\n"
     ]
    }
   ],
   "source": [
    "# mlp_DIMA = MLP_DIMA()\n",
    "# mlp_DIMA.load_state_dict(torch.load(PATH_), strict=False)\n",
    "\n",
    "time_ = []\n",
    "acc = []\n",
    "# for i in range (1):\n",
    "start_time = time.time()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = mlp_DIMA(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "time_.append(time.time() - start_time)\n",
    "acc.append(100 * correct / total)\n",
    "#     print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#         100 * correct / total))\n",
    "\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print('ACC:',np.average(np.array(acc)))\n",
    "print('Time:',np.average(np.array(time_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
